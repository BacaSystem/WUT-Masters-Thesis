\newpage % Rozdziały zaczynamy od nowej strony.
\section*{Cel Pracy} \label{ss:Cel Pracy}

\noindent
Dynamiczny rozwój technologii oraz systemów sztucznej inteligencji umożliwił
realizację zaawansowanych i skomplikowanych obliczeniowo zadań bezpośrednio na urządzeniach mobilnych.
Postęp w architekturze modeli, metodach kompresji oraz wydajności układów (CPU/NPU) sprawił,
że aplikacje korzystające z AI stały się powszechne w środowisku mobilnym.
Równolegle, wielcy dostawcy usług chmurowych udostępniają najnowocześniejsze modele AI,
oferujące zaawansowane możliwości o niespotykanej wcześniej jakości i skali.
Rozwiązania te niosą jednak ze sobą zależność od zewnętrznej infrastruktury oraz wiążą się
z kwestiami prywatności, bezpieczeństwa i opłat subskrypcyjnych.

Na tym tle szczególne znaczenie zyskuje zadanie automatycznego generowania opisów obrazów 
(image captioning), łączące zaawansowane przetwarzanie obrazu z generowaniem języka naturalnego.
Technologia ta znajduje zastosowanie w wielu aspektach, od wsparcia osób z dysfunkcją wzroku,
przez automatyczną kategoryzację treści, aż po integrację z asystentami głosowymi.


W obliczu tych możliwości twórcy aplikacji mobilnych stają przed dylematem wyboru
między wdrażaniem lokalnych modeli sztucznej inteligencji, a integracją z usługami chmurowych dostawców.

Celem niniejszej pracy jest przeprowadzenie kompleksowej analizy porównawczej modeli działających 
w warunkach lokalnych oraz chmurowych w kontekście generowania opisów obrazów na urządzeniach 
z systemem Android. Badanie obejmuje porównanie trzech modeli lokalnych uruchamianych przez środowisko
ONNX Runtime (Florence-2, ViT-GPT2, BLIP) oraz trzech usług chmurowych udostępnianych przez interfejs
API (OpenAI GPT-4o mini, Azure Computer Vision, Google Gemini 2.5 Flash Lite).

Analiza efektywności poszczególnych modeli opiera się na dwóch komplementarnych aspektach:
metrykach wydajnościowych (czas generowania odpowiedzi, zużycie pamięci RAM, pobór energii, koszty wywołań API)
oraz metrykach jakościowych (poprawność generowanych opisów mierzona wskaźnikami CIDEr, SPICE, METEOR, BLEU).
Zebrane w ten sposób dane posłużą do sformułowania popartych empirycznie rekomendacji doboru rozwiązań
sztucznej inteligencji w zależności od przeznaczenia projektowanej aplikacji mobilnej.

Do realizacji powyższych celów zaprojektowano i zaimplementowano platformę badawczą CaptionLab, która
umożliwia prowadzenie badań, zbieranie metryk oraz zautomatyzowane testy na dużych zbiorach danych.
Architektura platformy badawczej została opracowana z myślą o elastyczności i rozszerzalności,
dzięki jednolitemu podejściu do implementacji poszczególnych modeli w formie osobnych providerów.

Ostatecznie praca dostarcza nie tylko analityczną wiedzę odnośnie strategii wdrażania systemów 
sztucznej inteligencji w środowisku mobilnym, ale także funkcjonalną platformę badawczą, która
może służyć jako fundament dla dalszych badań lub jako funkcjonalne narzędzie przy podejmowaniu
decyzji architektonicznych w projektowaniu aplikacji mobilnych.



\newpage
\section{Wstęp}\label{s:Wstep}

\noindent
Systemy sztucznej inteligencji w ostatnich latach przeszły znaczną ewolucję od naukowych koncepcji
do powszechnie wykorzystywanych narzędzi, które zrewolucjonizowały wiele dziedzin życia i przemysłu.
AI znalazła zastosowanie i zmieniła funkcjonowanie całych sektorów gospodarki, począwszy od technologii i
rozrywki przez dziennikarstwo, kończąc na finansach, czy medycynie. Według danych Presedence Research globalny rynek AI
osiągnął wartość ponad 750 miliardów USD w 2025 roku, a prognozowany dalszy wzrost, przewiduje wzrost
do prawie 3.7 bilionów USD do roku 2034 \cite{ai_market_precedence_2025}.

W spektrum zastosowań sztucznej inteligencji szczególnie wyróżnia się zadanie automatycznego generowania
opisów obrazów (image captioning) jako jedno z bardziej złożonych wyzwań łączących przetwarzanie obrazu,
kategoryzację wizualną oraz analizę kontekstu z generowaniem języka naturalnego. Systemy image captioning,
oparte na architekturach encoder-decoder \cite{show_and_tell_vinyals2015}, znajdują zastosowanie w wielu obszarach,
od wsparcia osób z dysfunkcją wzroku, przez automatyczną kategoryzację treści, aż po integrację
z asystentami głosowymi.

Rozwój technologii uczenia maszynowego umożliwił znaczący postęp w dziedzinie image captioning.
Systemy AI zyskały nowe możliwości dzięki innowacyjnym architekturom modeli oraz narzędziom
ułatwiającym deweloperom wdrażanie zaawansowanych rozwiązań.
Modele oparte na architekturze transformerów wizyjnych (Vision Transformer, ViT)
wypierały tradycyjne sieci konwolucyjne (Convolutional Neural Networks, CNN), oferując lepsze możliwości 
rozpoznawania i kwalifikacji obrazów \cite{vit_dosovitskiy2021}. Pojawienie się technologii jednolitych 
formatów modeli takich jak ONNX (Open Neural Network Exchange) umożliwiło łatwiejszą wymianę i wdrażanie 
zaawansowanych modeli AI w środowiskach o ograniczonych zasobach \cite{onnx_icsme_openja2022}, podczas gdy 
popularyzacja sieci 5G oraz rozwój chmurowego przetwarzania danych pozwoliło na korzystanie z potężnych
modeli AI poprzez interfejsy API (Application Programming Interface), eliminując potrzebę lokalnego przechowywania
i przetwarzania danych \cite{edge_computing_shi2016}.

Jednym z najbardziej dynamicznie rozwijających się obszarów zastosowań sztucznej inteligencji
są aplikacje i systemy mobilne. Współczesne urządzenia mobilne, niegdyś pełniące funkcję jedynie
narzędzi komunikacji i prostej rozrywki, dziś wyposażone są w zaawansowane układy obliczeniowe
(Neural Processing Unit, NPU) umożliwiające przetwarzanie złożonych modeli AI bezpośrednio na urządzeniach. Według raportu z 2025 roku opublikowanego przez Statista, na świecie jest ponad 7 miliardów
zarejestrowanych w sieci smartfonów, co przekłada się na niemal 80\% globalnej populacji \cite{smartphone_users_2025}.
Ta masywna baza użytkowników połączona z ciągle rosnącą mocą obliczeniową układów mobilnych, sprawia,
że platformy mobilne stają się kluczowym obszarem dla wdrażania rozwiązań opartych na sztucznej inteligencji.


Wybór aplikacji mobilnych jako obszaru badań nad efektywnością modeli AI jest konsekwencją szeregu specyficznych uwarunkowań środowiskowych.
Po pierwsze, urządzenia mobilne charakteryzują się ścisłymi ograniczeniami sprzętowymi, takimi jak limitowana ilość pamięci RAM, mocy obliczeniowej, 
czy ograniczonym źródłem zasilania. Po drugie, urządzenia funkcjonują w warunkach zmiennej jakości połączeń sieciowych, co podważa niezawodność rozwiązań 
zależnych wyłącznie od infrastruktury chmurowych dostawców. Po trzecie, kwestia prywatności i bezpieczeństwa danych użytkownika nabiera szczególnego 
znaczenia w kontekście osobistych urządzeń z dostępem do bardzo wrażliwych danych. Czynniki te powodują, że architektura systemów AI na platformach mobilnych
musi uwzględniać precyzyjny dobór rozwiązań, miejsca przetwarzania danych oraz strategii zarządzania zasobami.

W kontekście tych ograniczeń zarysowuje się istotny kompromis między podejściem lokalnym a chmurowym.
Modele uruchamiane lokalnie oferują działanie bez połączenia z siecią,
przewidywalność czasu odpowiedzi oraz silniejszą ochronę prywatności. Z drugiej strony usługi chmurowe oferują dostęp 
do najnowszych, dużych generatywnych modeli bez konieczności ich instalacji, aktualizacji, czy obciążania pamięci urządzenia,
kosztem zależności od sieci, kosztów subskrypcyjnych i zewnętrznego przetwarzania danych. Badania Yuyi Mao i innych wykazały,
że wybór miejsca wykonywania obliczeń (edge vs. cloud) ma istotny wpływ na opóźnienie, zużycie energii
oraz przepustowość systemu \cite{edge_vs_cloud_mao2017}. W przypadku środowiska o ograniczonych zasobach, 
chcąc jednocześnie oferować możliwie jak najlepszą jakość usługi, wybór odpowiedniego rozwiązania staje się kluczowym zadaniem projektowym dla twórców aplikacji mobilnych.


Brak kompleksowych badań porównawczych utrudnia jednak podejmowanie świadomych decyzji architektonicznych.
Niniejsza praca ma na celu wypełnienie tej luki poprzez przeprowadzenie szczegółowej analizy wydajnościowej
i jakościowej reprezentatywnych modeli lokalnych i chmurowych do generowania opisów obrazów w środowisku
mobilnym Android.


\subsection{Wymagania projektowe}\label{ss:Wymagania Projektowe}

\noindent

Głównym celem badawczym niniejszej pracy jest przeprowadzenie kompleksowej analizy efektywności 
lokalnych oraz chmurowych rozwiązań sztucznej inteligencji w zadaniu generowania opisów obrazów (image captioning) 
na platformie mobilnej Android oraz sformułowanie rekomendacji doboru strategii wdrożeniowej 
w zależności od specyfiki i przeznaczenia projektowanych aplikacji mobilnych.

Kompleksowe porównanie efektywności modeli sztucznej inteligencji
w badanym kontekście wymagało
zdefiniowania problemu badawczego, doboru reprezentatywnych modeli oraz opracowania metodologii badawczej 
umożliwiającej obiektywną analizę poszczególnych modeli poprzez analizę zebranych w trakcie badań metryk.


Nim przystąpiono do realizacji głównego celu badawczego i wybrano poszczególne rozwiązania modeli sztucznej inteligencji
do analizy, należało zgłębić temat image captioning'u, poznać sam mechanizm działania, a także zrozumieć architekturę poszczególnych systemów 
dostępnych na rynku. W tym celu przeprowadzono szczegółową analizę literatury oraz dokumentacji technicznej
dotyczącej zarówno klasycznych, jak i współczesnych podejść do zadania automatycznego generowania opisów obrazów.

Na bazie tej wiedzy, dokonano selekcji reprezentatywnych modeli AI, różniących się architekturą, podejściem do przetwarzania danych, a także miejscem wykonywania obliczeń (lokalne vs. chmurowe). 
Wybrane modele miały pokrywać szerokie spektrum dostępnych rozwiązań,
umożliwiając w ten sposób analizę technologii o różnych podejściach i możliwościach.

Nastepnie, mając wyselekcjonowane rozwiązania, zaprojektowano i zaimplementowano dedykowaną platformę badawczą, zdolną do wdrażania
i testowania różnorakich modeli AI w zadaniu image captioning'u. Platforma ta, poza wsparciem dla uruchamiania różnorodnych modeli, musiała także umożliwiać 
zbieranie precyzyjnych metryk, niezbędnych do obiektywnej analizy efektywności poszczególnych rozwiązań.

Opracowanie metodologii badawczej obejmowało zdefiniowanie zestawu metryk wydajnościowych i jakościowych, 
procedur pomiarowych oraz protokołu testowego, pozwalającego na zebranie odpowiednich danych, które w dalszej kolejności 
będą służyć do obiektywnej oceny efektywności badanych modeli AI.

Z opracowaną metodologią i sformułowanymi wymaganiami projektowymi, przystąpiono do realizacji badań, przeprowadzając serię eksperymentów
badawczych, zbierając dane dotyczące parametrów wydajnościowych i jakościowych dla wybranych lokalnych i chmurowych modeli sztucznej inteligencji.

Ostatnim i zarazem kluczowym etapem była wizualizacja i interpretacja uzyskanych wyników badań, identyfikacja kompromisów między wydajnością, a jakością
generowanych opisów oraz sformułowanie rekomendacji doboru strategii wdrożeniowej w zależności od specyfiki i wymagań projektowanej aplikacji mobilnej.


Wyżej sformułowane wymagania zebrano i przedstawiono w formie poszczególnych celów badawczych, których realizacja prowadzi do osiągnięcia głównego celu pracy.
Każdy z wyróżnionych niżej celów odpowiada kolejnym rozdziałom pracy, w których szczegółowo opisano podejście do realizacji i osiągnięcia poszczególnych celów.

\begin{enumerate}[leftmargin=*, label=\textbf{C\arabic*.}, itemsep=3pt]
    \item Przedstawienie teoretycznych podstaw automatycznego generowania opisów obrazów, analizy 
    architektur modeli AI stosowanych w zadaniu image captioning'u oraz identyfikacja kluczowych różnic 
    między strategiami wdrażania lokalnego i chmurowego w kontekście aplikacji mobilnych.
    
    \item Zaprojektowanie i implementacja dedykowanej platformy badawczej \textquote{CaptionLab} umożliwiającej 
    przeprowadzenie badań porównawczych modeli lokalnych i chmurowych w środowisku 
    Android z zapewnieniem precyzji pomiarów oraz powtarzalności testów.
    
    \item Opracowanie metodologii badawczej obejmującej definicję zestawu metryk wydajnościowych i jakościowych, 
    procedur pomiarowych oraz protokołów testowych pozwalających na obiektywną ocenę efektywności badanych 
    modeli AI.
    
    \item Przeprowadzenie serii eksperymentów badawczych oraz zebranie danych dotyczących parametrów wydajnościowych 
    (czas inferencji, zużycie pamięci, pobór energii, koszty operacyjne) i jakościowych (metryki CIDEr, SPICE, 
    METEOR, BLEU) dla wybranych modeli lokalnych i chmurowych.
    
    \item Interpretacja uzyskanych wyników badań, identyfikacja kompromisów między wydajnością, a jakością 
    generowanych opisów oraz sformułowanie rekomendacji doboru strategii wdrożeniowej w zależności od 
    specyfiki i wymagań projektowanej aplikacji mobilnej.
\end{enumerate}


\subsection{Struktura Pracy}\label{ss:Struktura Pracy}

\noindent
Wskazane cele i zidentyfikowane problemy badawcze w sekcji \ref{ss:Wymagania Projektowe}. \textit{Wymagania projektowe} zdefiniowały 
podział pracy na poszczególne jednostki redakcyjne, z których każda odpowiada realizacji kolejnych celów badawczych.

Rozdział \ref{s:Modele}. \textit{Modele i technologie AI do generowania opisów obrazów} przedstawia szczegółowy opis teoretycznych podstaw automatycznego generowania opisów obrazów, ewolucji architektur
oraz mechanizmów działania systemów image captioning'u. Zawarto w nim także omówienie kluczowych różnic między strategiami wdrażania lokalnego i chmurowego,
a także charakterystykę wybranych modeli sztucznej inteligencji wykorzystanych w badaniach.

Szczegóły architektury i implementacji platformy badawczej zostały opisane
w rozdziale \ref{s:Aplikacja badawcza CaptionLab}. \textit{Aplikacja badawcza CaptionLab}. W ramach pracy napisany został dedykowany system badawczy 
\textquote{CaptionLab}, zdolny do przeprowadzania
testów porównawczych między różnymi modelami AI w środowisku Android, jednocześnie zbierając potrzebne 
dane do dalszej analizy. 

W rozdziale \ref{s:Metodologia badan}. \textit{Metodologia badania} przedstawiono proces projektowania i przeprowadzania 
eksperymentów badawczych, metodologię pomiarów, opis wykorzystanych w analizie metryk, a także sposób wyznaczania 
metryk jakościowych oceniających generowane opisy obrazów, na podstawie popularnych metod oceny jakości generowanego tekstu przez AI.

Wszelkie dane zebrane podczas przeprowadzania badań zostały przedstawione w rozdziale \ref{s:Wyniki badan}. \textit{Wyniki badań},
aby na ich podstawie dokonać analizy i wysnuć odpowiednią interpretację na łamach rozdziału \ref{s:Interpretacja wynikow badan}. \textit{Interpretacja wyników badań}.

Rozdział \ref{s:Podsumowanie}. \textit{Podsumowanie} zawiera końcowe wnioski z przeprowadzonych badań oraz wskazuje kierunki dalszych badań w obszarze wdrażania systemów
image captioning'u  opartych o AI na platformach mobilnych.

